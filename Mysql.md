## 执行一条 SQL 查询语句，期间发生了什么


## Mysql 架构图

    连接器: 身份认证和权限相关(登陆Mysql的时候)
    查询缓存: 执行查询语句的时候，会先查询缓存(Mysql8.0被废除)
    分析器: 没有命中缓存的话，SQL语句会经过分析器，进行SQL语句分析，查看SQL语句要干啥，再检查SQL语句语法是否正确
    优化器: 按照Mysql认为最优的方案去执行
    执行器: 执行语句，从存储引擎返回数据
    插件式存储引擎: 负责数据的存储和读取，采用的时插件式架构，支持InnoDB MYISAM Memory等多种存储引擎

## Mysql 存储引擎

- Mysql 默认的引擎时 InnoDB,所有的引擎中只有 InnoDB 是事务性存储引擎，只有它支持事务.

## Mysql 存储引擎架构

    采用的插件式架构，支持多种存储引擎，可以为不同的表设置不同的存储引擎。存储引擎是基于表的，不是基于数据库的。

## MyISAM InnoDB 的区别

    - MyISAM只有表级锁，InnoDB支持行级锁和表级锁，默认为行级锁，也就是说MyISAM一锁就是锁住了整张表，在并发写下比较低效率
    - MyISAM不支持事务，InnoDB支持事务，具有提交和回滚事务的能力
    - MyISAM不支持外键，InnoDB支持外键。不建议在数据库层面使用外键
    - MyISAM不支持数据库异常崩溃后的安全恢复， InnoDB支持
    - MyISAM不支持MVCC, InnoDB支持
    - 两者索引实现方式不一样  InnoDB数据本身就是索引文件  MyISAM索引文件和数据文件是分离的
    - 性能有差别

## Mysql 索引

    https://blog.csdn.net/sinat_40770656/article/details/114339535

## Mysql 查询缓存

    - 执行查询语句的时候，会先查询缓存。不过,Mysql8.0版本后移除，功能不太实用
    - 缓存虽然能够提升数据库的查询性能，但是缓存的同时也带来了额外的开销，每次查询后都要做一次缓存操作，失效后还要销毁。因此对于查询缓存，应该谨慎开启。

## Mysql 日志

    https://blog.csdn.net/qq_50596778/article/details/123232708
    - redo log :  物理日志，记录内容在某个数据页上做了什么修改   保持事务的持久性
      - 重做日志，InnoDB存储引擎独有的，他让Mysql拥有了崩溃恢复的能里，mysql实例挂了或者宕机了，重启时，InnoDB存储引擎会使用redo log 恢复数据，保证数据的持久性和完整性
      - 1.第一步加载数据到缓冲池中 Buffer pool
      - 2.直接更新缓存数据，同时会把在这个数据页做得修改记录到重做日志缓存 redo log buffer ,接着刷盘到redo log文件中，理想情况下，事务一提交就会进行刷盘
    - bin log:  逻辑日志，记录内容是语句的原始逻辑，属于Mysql server层   保持事务数据的一致性
      - 只要表发生了更新，都会产生binlog日志，会记录所有涉及更新数据的逻辑操作，并且是顺序写
      - 用来做数据库的数据备份，主备，主主，主从，依靠binlog来同步数据，保证数据一致性
      - 写入机制: 事务执行过程中，先把日志写到binlog cache 事务提交的时候，再把binlog cache写到binlog文件中，
      - 把日志文件写到文件系统的page cache 并没有把数据持久化到磁盘，速度比较快  机器宕机 page cache里的日志文件会丢失
      - fsync是把数据持久化到磁盘的操作
      - 在执行更新语句过程，会记录redo log 与binlog两块日志，以基本的事务为单位，redo log在事务执行过程中可以不断写入，而binlog只有在事务提交时才写入，两者的写入时机不同
    - 为什么需要引入redo log prepare预提交状态？
      - 当先写redo log直接提交，再写binlog。 当写完redo log 后，机器挂了，binlog日志没有写入，重启机器之后，机器会通过redo log进行数据恢复，但是binlog中没有记录该数据，那么再进行机器备份或者主从复制时，就会丢失掉该条数据
      - 先写binlog 再写redo log 。当先写完binlog，redo log没有写入，此时机器挂掉了，机器重启，根据redo log是无法恢复前面加入的数据，那么产生数据不一致的情况。
      - 假设当redo log处于预提交的状态，binlog也写完了，这个时候发生异常重启
        - 判断redo log是否完整，完整则立即提交
        - 如果redo log只是预提交但不是commit状态，这个时候就会去判断binlog是否完整，如果完整则进行事务提交，不完整则回滚事务。
    - undo log : 回滚日志   保持事务的原子性
      - 所有的事务进行的修改都会先记录到这个回滚日志中，然后再执行相关的操作。如果再执行过程中遇到异常，可以利用回滚日志中的信息将数据回滚到修改前的样子
      - 回滚日志会先将数据持久化到磁盘中，可以保证数据库宕机重启后，还能通过查询回滚日志回滚之前未完成的事务

## Mysql 事务

    - 事务就是逻辑上的一组操作，要么都执行，要么都不执行
    - 数据库事务: 数据库事务可以保证多个对数据库的操作构成一个逻辑上的整体，构成这个逻辑上的整体的这些数据库操作遵循: 要么都执行，要么都不执行
    - ACID特性 AID是手段 C是目的
      - 原子性(Atomicity) 事务时最小的执行单位，不可分割。事务的原子性保证动作要么都执行，要么都不执行
      - 一致性(Consistency) 执行事务前后，数据保持一致
      - 隔离性(Isolation) 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库时独立的
      - 持久性(Durability) 一个事务提交之后，对数据库的数据改变时持久的，不会因数据库发生故障出现任何影响

- 并发事务带来的影响:
  - 脏读: 一个事务读取数据并进行修改，当前事务还没有提交，另外一个事务读取了这个还未提交的数据，前一个事务突然回滚，导致数据最终是没有提交到数据库。那么第二个事务读取到的就是脏数据。
  - 丢失修改: 第一个事务读取了数据，另一个事务也读取了数据，前一个事务对数据进行修改，第二个事务也对数据进行修改，那么第一个事务提交的修改结果丢失，称为丢失修改
  - 不可重复读: 一个事务多次读取同一数据。在该事务没有结束时，另一个事务也访问该数据，第二个事务在第一个事务两次的读之间，对数据进行了修改，导致第一个事务两次读取的数据可能不太一样。那么一个事务内两次读到的数据不一样称为不可重复读
  - 幻读: 类似不可重复读，第一个事务读取几行数据，第二个事务插入了一些数据，在随后的查询中，第一个事务会发现一些原来不存在的记录，如同发生幻觉。
  - 不可重复度和幻读的区别
    - 不可重复读的重点在于内容修改或者记录减少 比如多次读取一条记录发现其中某些记录的值被修改
    - 幻读的重点在于记录新增 多次执行同一条查询语句时，发现查到的记录增加了
    - 执行 delete 和 update 操作时，可以直接对记录加锁，保证事务安全。执行 insert 操作时，记录锁只能锁住已经存在的记录，为了避免插入新纪录，需要依赖间隙锁。因此执行 insert 操作需要依赖记录锁和间隙锁保证不出现幻读。

### 并发事务的控制方式

    - 锁: 悲观锁控制模式 通过读写锁实现并发控制
      - 共享锁(S锁) 事务在读取记录的时候获取共享锁，允许多个事务同时获取资源(锁兼容)
      - 排他锁(X锁) 写锁/独占锁 事务在修改记录的时候获取排他锁，不允许多个事务同时获取。一个记录已经被加了排他锁，其他事务不能再对这条记录加任何类型的锁(锁不兼容)
      - 排他锁与任何锁都不兼容，共享锁仅仅和共享锁兼容
      - 根据细粒度的不同，可以分为表级锁和行级锁 行级锁的粒度更小，仅对相关的记录上锁即可(对一行或者多行记录加锁)
    - MVCC 多版本并发控制 乐观控制的模式
      - 对一份数据存储多个版本，通过事务的可见性来保证事务能够看到自己应该看到的版本。通常会有一个全局的版本分配器为每一行数据设置版本号，版本号是唯一的
      - 每个事务读到的数据版本可能是不一样的，在同一个事务中，用户只能看到该事务创建Read View之前已经提交的修改和该事务本身做的修改
      - undo log 用于记录某行数据的多个版本的数据
      - read view 和隐藏手段用来判断版本数据的可见性

### 事务隔离级别 Mysql 默认事务隔离级别是可重复读

    - 读取未提交: 允许读取尚未提交的数据变更，可能导致脏读，幻读或者不可重复读
    - 读取已提交: 允许读取并发事务已经提交的数据，可以防止脏读，可能存在幻读或者不可重复读的问题
    - 可重复读: 对同一个字段的多次读取结果是一致的，除非数据本身被事务所修改，可以阻止脏读和不可重复读，可能发生幻读
    - 可串行化: 完全服从ACID的隔离级别，可以防止脏读，不可重复读和幻读
    - 可串行化隔离级别是通过锁来实现的，可重复读和读取已提交是基于MVCC实现的，同时也可能用到锁机制来实现隔离级别。

## Mysql 锁

    - 锁是一种常见并发事务的控制方式
    -
    - 表级锁: 锁定粒度最大的一种锁，针对非索引字段家的锁，对当前操作的整张表加锁，实现简单，资源消耗少，加锁快，不会出现死锁。触发锁冲突的概率较高，高并发效率较低。
    - 元数据锁：
      - 对一张表进行CRUD操作，加的是MDL读锁  MDL读锁会阻塞MDL写锁
      - 对一张表进行结构变更操作，加的是MDL写锁  MDL写锁会阻塞MDL读锁
    - 意向锁
      - 在InnoDB引擎的表里对某些记录加上共享锁之前，需要先在表级别上加上一个意向共享锁
      - 在InnoDB引擎的表里对某些记录加上独占锁之前，需要先在表级别上加上一个意向独占锁
      - 意向锁和意向锁之间不会发生冲突，同时也不会和行级的共享锁和独占锁发生冲突，只会和共享锁表和独占锁表发生冲突
      - 如果没有意向锁，那么加独占锁表时，就需要遍历表中的所有记录，查看是否右记录存在独占锁，这样效率很慢
      - 当存在意向锁时，由于在对记录加独占锁之前，先会加上表级别的意向独占锁，那么在加独占表锁时，直接查询该表是否存在意向独占锁，如果有就意味着表中已经有记录被加上了独占锁，不需要去遍历表里面的记录
      - 意向锁的目的是为了快速判断表里是否有记录被加锁
    - AUTO-INC锁
    -
    - 行级锁: 锁定粒度最小的一种锁，针对索引字段加的锁，只针对当前操作的行记录加锁。行级锁和存储引擎有关，是在存储引擎层面实现的
    - 当我们执行UPDATE DELETE 语句时，如果WHERE条件中字段没有命中唯一索引或者索引失效时，就会导致扫描全表对表中的所有记录进行加锁。有时候即使使用了索引也会出现全表扫描，Mysql优化器的原因
    - InnoDB行锁是通过对索引数据页上的记录加锁实现的
      - 记录锁: 属于单个行记录上的锁 锁住的是表中的一条记录，记录有共享锁和排他锁之分
      - 间隙锁: 锁定一个范围，不包括记录本身 只存在于可重复读隔离级别，目的是为了解决可重复读隔离级别幻读的现象
      - 临键锁: 记录锁+间隙锁 锁定一个范围，包括记录本身主要为了解决幻读问题。记录锁只能锁住已经存在的记录，为了避免插入新纪录，需要依赖间隙锁
      - 插入意向锁：属于行级锁 一条事务在插入一条记录时，需要判断插入位置是否已经被其他事务加了间隙锁。如果有的话，插入操作被阻塞，这期间插入一个插入意向锁，表明有事务想在某个区间插入新纪录，但是现在处于等待状态
      - 在可重复读的隔离级别下，行级锁默认使用临键锁，但如果操作的索引时唯一索引或者主键，会将临键锁降级为记录锁，仅锁住索引本身，而不是范围

### 意向锁

    - 如果需要用到表锁的话，如何判断表中的记录没有行锁呢，利用意向锁可以快速判断是否可以对一个表使用表锁
    - 意向共享锁: 事务有意对表中的某些记录加共享锁，加共享锁之前必须先取得该表的意向共享锁
    - 意向排他锁: 事务有意对表中的某些记录加排他锁，加排他锁之前必须先取得该表的意向排他锁
    - 用户无法手动操作意向锁，在位数据行加共享/排他锁之前，InnoDB会先获取数据行所在的表的对应意向锁
    - 意向锁之间互相兼容 表级别的共享锁 排他锁 意向锁不会与行级别的共享锁和排他锁互斥

### 当前读和快照读

    - 快照读: 一致性非锁定读 就是单纯的select语句，快照即记录的历史版本，每行记录可能存在多个历史版本 通常做法是加一个版本号或者时间戳字段，在更新数据的同时版本号+1或者更新时间戳，查询时将当前可见的版本号与对应记录的版本号进行比对，如果记录的版本小于可见版本，表示该记录可见
      - 快照读情况下，如果读取的记录正在执行delete/update操作时，读取操作不会因此去等待记录上的排他锁释放，而是去读取行的一个快照。
      - 在RC级别下，对于快照数据，一致性非锁定读总是读取被锁定行的最新一份快照数据 在每个语句执行前都会重新生成一个Read View
      - 在RR级别下，对于快照数据，一致性非锁定读总是读取本事务开始时的行数据版本   启动事务时生成一个Read View 然后整个事务期间都在用这个Read View
    - 当前读: 一致性锁定读 就是给行记录加X锁或者S锁 还有insert update delete方法，读取到的是最新版本
    - 针对快照读，通过MVCC方式解决了幻读，因为可重复读隔离级别下，事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，即使中途有其他事务插入了一条数据，是查询不出来这条数据的，所以很好的解决了幻读的问题
    - 针对当前读，通过记录锁加间隙锁方式解决幻读，当执行select等语句时，会加上临键锁，如果有其他事务在这个临键锁范围内插入了一条记录，那么这个插入语句会被阻塞，无法成功插入，很好低避免了幻读问题。
    - 执行开始事务命令，并不意味着启动了事务
      - 第一种：begin/start transaction 命令；该命令不会立即启动事务，只有执行了增删查改操作的SQL语句之后，事务才会真正启动
      - 第二种：start transaction with consistent snapshot 命令； 立马启动事务
    - Mysql可重复读隔离级别并没有彻底解决幻读，只是很大程度上避免了幻读现象的发生。要避免特殊场景下发生幻读，就是尽量在开启事务之后，马上执行select...for update这类当前读的语句，因为它会对记录加next-key lock, 避免其他事务插入一条新纪录。

- 锁全表问题
  - 在线上在执行 update、delete、select ... for update 等具有加锁性质的语句，一定要检查语句是否走了索引，如果是全表扫描的话，会对每一个索引加 next-key 锁，相当于把整个表锁住了。对于查询的语句时索引查询时，并不会走全表扫描，因此不会把整张表给锁住
  - 在 Mysql 的可重复读隔离级别下，针对当前读的语句会对索引加记录锁+间隙锁，这样可以避免其他事务执行增删改时导致的幻读操作

## Mysql 性能优化

    - Mysql可以直接存储文件吗？
      - 可以但不推荐 能直接存储文件对应的二进制数据，但是会严重影响数据库性能，消耗过多的存储空间
    - Mysql如何存储IP地址
      - 将IP地址转换成整型结构，性能更好，占用内存小
      - INET_ATON() 把IP地址转为无符号整型
      - INET_NTOA() 把整型的ip转为地址

- 数据库三范式
  - 第一范式：列的原子性
  - 第二范式：实体的属性完全依赖于主关键字 将一个表最有关联的属性放在一起
  - 第三范式：任何非主属性不依赖于其他非主属性 消除传递依赖
- 索引
  - 索引的出现是为了调高数据的查询效率，就像书的目录一样，同样索引也会带来负面影响，创建索引和维护索引需要耗费时间，这个时间随着数据量的增加而增加
  - 建立索引的原则
    - 在最频繁使用的，用以缩小查询范围的字段上建立索引
    - 在频繁使用，需要排序的字段上建立索引
    - 重复值较多查询较少的字段中，不建立索引
    - 特殊的数据类型，不宜建立索引如文本字段
  - 分类
    - 数据结构分类 B+树索引 哈希所系 全文索引
    - 物理存储分类 聚簇索引（主键索引） 二级索引（辅助索引）
    - 字段特征分类： 主键索引 唯一索引 普通索引 前缀索引
    - 字段个数分类: 单列索引 联合索引
  - InnoDB 存储引擎根据不同场景选择不同的列作为索引
    - 如果有主键，默认会使用主键作为聚簇索引的索引键（key）；
    - 如果没有主键，就选择第一个不包含 NULL 值的唯一列作为聚簇索引的索引键（key）；
    - 在上面两个都没有的情况下，InnoDB 将自动生成一个隐式自增 id 列作为聚簇索引的索引键（key）；
    - 其他索引就都是辅助索引，也成为二级索引或者非聚簇索引
    - 联合索引：通过将多个字段组合成一个索引，在使用联合索引时，存在最左匹配原则，按照最左优先的方式及逆行索引的匹配。
      - 遵循最左前缀原则 使用时最好最常用作为检索或者排序的列放在最左边以此递减
      - 联合索引的最左匹配原则会一直向右匹配直到遇到范围查询就会停止匹配：范围查询的字段可以用到联合查询，但是范围查询字段的后面的字段无法用到联合索引
      - 联合索引的最左匹配原则，在遇到范围查询（如 >、<）的时候，就会停止匹配，也就是范围查询的字段可以用到联合索引，但是在范围查询字段的后面的字段无法用到联合索引。注意，对于 >=、<=、BETWEEN、like 前缀匹配的范围查询，并不会停止匹配
  - 索引存储数据结构
    - 哈希表：以一种键值对的存储数据的结构，哈希表只适用于等值结构的查询
    - 有序数组：只适用于静态存储引擎，数组是适合于查询的，但是增加或者删除数据是及其麻烦的
    - 二叉查找树：可以利用二分查找进行数据的 1 查询，但是在一些极端情况下会退化成链表
    - 平衡二叉树：可以利用树的结构进行存储，但如果每个结点存储的数据太少，从索引中找到我们需要的数据，就需要访问更多的结点啊，更多 IO 操作。
    - 多路平衡二叉树：也就是 B 树 每个结点都包含着键值和数据，所有结点时存储着数据。但是 B 树不支持范围查询的快速查找，查找到一个数据之后，就需要回到根节点重新遍历查找，需要从根节点遍历多次。如果 data 存储的是行数据，行的大小随着列数增多所占空间变大，那么一页存储的数据变少，树相应就会变高，磁盘 IO 次数变多
    - B+树：与 B 树的主要区别是非叶子节点是否存储数据的问题。只有叶子节点存储数据，非叶子节点存储键值，叶子节点之间使用双向指针连接，底层叶子节点形成一个双向有序列表
      - B+树叶子节点才会存放实际数据（索引+记录），非叶子节点只会存放索引
      - 所有索引都会在叶子节点出现，叶子节点之间构成一个有序链表
      - 非叶子节点的索引也会同时存在在子节点中，并且是在子节点中所有索引的最大（或最小）
      - 非叶子节点中有多少个子节点，就有多少个索引
      - 效率更加稳定
      - 排序能力更强
      - 磁盘读写能力相对于 B 树更强
      - 扫库扫表能力更强，只需要遍历叶子节点就可以获取数据
    - 主键索引的 B+Tree 和二级索引的 B+Tree 区别
      - 主键索引的 B+树的叶子节点存放的是实际数据，所有完整的用户记录都存放在主键索引的 B+树
      - 二级索引的 B+树的叶子节点存放的是主键值，而不是数据
      - 当使用二级索引查询商品时，会先检索二级索引中的 B+树的索引值，找到对应的叶子节点，然后获取主键值，然后再通过主键索引中的 B+树查询到对应的叶子节点，获取整行数据，该过程称为回表，要查询两个 B+树才能获取数据
      - 当然如果在查询的时候使用了二级索引，如果查询的数据能在二级索引里查询到，那么就不要回表，这个过程就是覆盖索引。
  - 非聚簇索引
  - 聚簇索引
  - 索引下推
    - 一个比较特殊的查询条件：where a=1 and c=3
    - 5.5 版本之前，前面的 a 会走索引，在联合索引中找到主键值之后开始回表，到主键索引读取数据行，Server 层会从存储引擎层获取到数据行后，然后在 Server 比对 c 字段的值
    - 5.5 版本之后，截断的字段不会在 Server 层进行条件判断，而是会被下推到存储引擎层进行条件判断，在索引的遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，再返还给 Server 层，从而减少回表次数，也就是索引下推
- 优化索引的方法
  - 前缀索引优化：为了减小索引字段大小，可以增加一个索引页中存储的索引值
  - 覆盖索引优化：避免回表 不需要查询包含整行记录的所有信息，减少 I/O 操作
  - 主键索引最好是自增的：
    - 每次插入一条新纪录都是追加操作，按顺序的，不需要重新移动数据，但是使用非自增主键，可能导致插入到现有数据页中间的位置，不得不移动其他数据来满足新数据的插入，甚至需要将一个页面的数据复制到另一个页面，也就是页分裂。页分裂可能会导致大量的内存碎片，导致所以结构不紧凑，影响查询效率。
    - 二级索引的叶子节点存放的是主键值，主键字段越小，意味着二级索引的叶子节点越小，占用空间小
  - 索引最好设置为非 NULL 的
  - 防止索引失效
- 索引失效的情形
  - 对索引使用左或者左右模糊匹配，右模糊匹配不会导致索引失效
  - 对索引使用函数 8.0 版本引入了索引函数
  - 对索引进行表达式计算
  - 对索引进行隐式类型转换 在 MYsql 中回到字符串和数字比较时，会自动把字符串转为数字，然后再进行比较，这个转换过程中会使用到函数
  - 联合索引非最左匹配
  - WHERE 语句中的 OR
- 查询性能的优化方法
  - 只返回必要的列
  - 只返回必要的行
  - 缓存重复查询的数据
  - 使用索引来覆盖查询
- count()函数的性能
  - count(1) count(\*) count(主键字段)在执行的时候，如果表中存在二级索引，优化器会使用二级索引进行扫描，如果只存在聚簇索引，则使用聚簇索引，同时 conut(主键字段)会对记录中的字段值进行读取
  - count(字段)会利用全表扫描的方式来进行统计。可以尝试给统计的字段建立一个二级索引。
  - 优化：
    - 采用近似值统计总数
    - 采用额外表保存计数值
- 水平切分和垂直切分

  - 水平切分是将同一个表中的记录拆分到多个结构相同的表中，将数据分布到集群的不同节点上，缓存单个数据库的压力
  - 垂直切分将表按列切分成多个表，按照列的关系密集程度进行切分

- 数据库读写分离
  - 主服务器处理写操作以及实时性要求比较高的读操作，而从服务器处理读操作
  - 主从服务器负责各自的读写，极大程度缓解了锁的争用
  - 增加冗余提高可用性
  - 从服务器使用 MyISAM 提升查询性以及节约系统开销
- 数据库读写分离的实现方案
  - 主要基于主从赋值通过路由的方式使应用对数据库的写请求只在主服务器上，而读请求在从服务器上
- MVCC 多版本并发控制
  - 数据库并发场景
    - 读-读：不存在任何问题
    - 读-写：有线程安全问题，可能会造成事务隔离性问题
    - 写-写：有线程安全问题，造成数据丢失
    - MVCC 解决读-写冲突的无锁并发控制，为事务分配单向增长的时间戳，为每个修改保存一个版本，版本与事务时间戳关联，读操作只读该事务开始前的数据库的快照
    - 在并发读写操作时，读操作不会阻塞写操作，写操作不会阻塞读操作，能够解决脏读，不可重复读 幻读的问题，不能解决数据丢失的问题
- 事务状态
  - 活跃状态：任何正在执行的事务都处于此状态，所作的更改存储在主内存的缓冲区中
  - 部分提交状态：执行上次操作后，事务进入部分提交状态
  - 失败状态：发生错误，事务进入失败状态
  - 终止状态：任何事务已达到失败状态，恢复管理器将数据库回滚到开始执行的原始状态
  - 提交状态：所有操作执行成功，部分提交状态的事务进入提交状态，不能进行事务回滚
- drop delete truncate 的区别
  - drop 是不可回滚的，直接从数据库中删除掉表和所有的数据行，索引和权限也会被删除，删除速度最快
  - delete 是可以回滚的，只是从表中删除全部或者部分数据，表的结构还在，删除速度慢
  - truncate 是不可以回滚的，从表中删除所有数据，表结构还在
- 分库分表
  - 数据库中的数据量是不可控的，库中表会越来越多，表中的数据也会越来越大，相应的数据操作也会带来巨大的开销。若不进行分布式部署，一台服务器的资源是有限的，最终数据库所能承载的数据量，数据处理能力都将遭遇瓶颈。从性能和可用性考虑，会及逆行数据库拆分处理。把原本存储与一个库的数据分块存储到多个库上，原本存储于一个表的数据分块存储到多个表中。
  - 事务问题：分库分表之后就成了分布式失误了，依赖数据库本身的分布式事务管理功能取执行事务，将付出高昂的代缴，应用程序取控制，会造成编程方面的负担
  - 分库分表之后原来逻辑性关联很强的数据划分到了不同的表和不同的库中，表的关联操作将受到限制，那么 JOIN 不能使用了，原本一次查询能完成的任务，可能需要多次查询才能完成
  - 造成额外的数据管理负担，最为常见的是数据的定位问题和数据的增删改查的重复执行问题。
- B 树 B+树

  - 当数据量非常大的时候，树的存储的元素数量是有限的，这样会导致二叉查找树结构由于树的深度过大而造成磁盘 I/O 读写过于频繁，进而导致查询效率降低。数据量过大会导致内存空间不够容纳平衡二叉树所有结点的情况。
  - B 树的每个节点都存储数据，而 B+树只有叶子节点才存储数据，所以查找相同数据量的情况下，B 树的高度更高，IO 更加频繁。数据库索引是存储在磁盘上的。当数据量大时就不能把整个索引全部加载到内存中了，只能注意加载每一个磁盘页（对应索引树的结点）

  1.MyISAM 和 InnoDB 区别

  - 存储结构：MyISAM 在磁盘上存储成三个文件，InnoDB 所有的表都保存在同一个数据文件大小中，大小是受限于操作系统文件的大小
  - 事务支持：MyISAM 不支持事务，InnoDB 支持事务
  - 最小锁粒度：MyISAM 只支持表级锁，更新时会锁住整张表，InnoDB 支持行级锁
  - 索引类型：MyISAM 索引为非聚簇索引，数据结构是 B 树 InnoDB 是聚簇索引，数据结构是 B+树
  - 外键支持：MyISAM 不支持外键，InnoDB 支持外键
  - 表的具体行数：MyISAM 保存了表的总行数，InnoDB 没有保存表的总行数
  - 主键必需 2.日志文件
  - 回滚日志
  - 重做日志
    - 记录的是关于每个页的更改的物理情况
  - 二进制日志
    - 记录一个事务的具体操作内容，该日志是逻辑日志

### Mysql 锁分类

#### 粒度分类

##### 全局锁

- 作用 确保整个数据库的一致性 全库备份和全库导出 尽量避免在生产环境使用全局锁
- 读锁（共享锁）
  - 阻止其他用户更新数据，但允许他们读取数据 不会破坏数据的一致性
- 写锁（排他锁）
  - 阻止其他用户读取和更新数据
- Flush tables with read lock 添加全局锁
- unlock tables jie'chu 全局锁

##### 表锁

- 开销小 加锁快 不会出现死锁 锁定力度大，发生锁冲突的概率最高，并发度最低
- 表共享读锁（表读锁）
- 表独占写锁（表写锁）
- 在 MyISAM 表的读操作中，会自动加上读锁，写操作会自动加上写锁
- 在 InnoDB 引擎中主要使用行锁来实现多版本并发控制
- 应用
  - 读密集型应用
  - 写操作不频繁的场景
  - 数据量不大的简单应用
  - 全表更新或者删除
- 风险
  - 性能下降 表锁会锁定整张表 高并发情况下导致大量的请求阻塞
  - 并发性能差
  - 可能导致锁等待或者超时
  - 写操作影响大
  - 死锁的可能性 本身表锁不会出现死锁 但操作多张表的时候可能会出现死锁

##### 行锁

- 相比于表级锁和页锁，行级锁的粒度更小，处理高并发事务时，能提供更好的并发性能和更少的锁冲突 行锁只能在事务中操作才有效 行锁是会出现死锁的
- 共享锁（读锁）
- 排他锁（写锁）
- 应用场景
  - 高并发的读写操作
  - 单行操作
  - 短期锁 对数据行进行短时间操作，防止长时间阻塞其他事务
  - 实现并发控制 确保数据一致性和隔离性的事务中
  - 复杂的事务处理
- 风险
  - 死锁
  - 锁升级 如果锁定的行数过多，会将锁升级为表锁
  - 锁等待 一个事务已经锁定了某行，其他试图访问这行的事务就必须等待
  - 资源消耗
  - 难以调试和排查
  - 事务隔离级别 不同的事务隔离级别会影响锁的行为和性能，根据具体应用场景来调整事务隔离级别

#### 模式分类

##### 乐观锁

- 应用场景
  - 低冲突环境 在多数情况瞎，数据并发修改的冲突较低 即同一时间内，同一条数据不会被多个事务同时修改
  - 读多写少的环境
  - 短事务操作
  - 分布式系统
  - 互联网应用
- 缺点
  - 冲突检测 高并发环境中，乐观锁可能导致大量的冲突 多个事务同一时间操作同一行，只有一个事务能提交成功
  - 处理开销 冲突发生时，需要进行回滚和重试 这可能增加系统的开销
  - 版本管理 需要通过版本号进行管理 要求系统正确地管理这些版本号
  - 编程复杂性

##### 悲观锁

- 应用场景
  - 写操作比较多的场景
  - 并发冲突高的场景 在并发冲突较高的场景，使用悲观锁可以避免重复尝试操作，提高系统的整体效率
  - 业务需要强一致性的场景 银行转账等金融业务 通常需要使用悲观锁，确保数据的一致性和准确性
- 缺点
  - 性能开销
  - 并发度低
  - 死锁
  - 锁超时

### 意向锁

- 意向锁是表锁，为了协调行锁和表锁的关系，支持多粒度（表锁和行锁）的锁并存
- 当事务 A 有行锁时，Mysql 会自动为该表添加意向锁，事务 B 如果想申请整个表的写锁，那么不需要遍历每一行判断是否存在行锁，而是直接判断是否存在意向锁，增强性能
- 为什么意向锁是表锁
  - 当我们需要加一个排他锁时，需要根据意向锁去判断表中有没有数据行被锁定（行锁）
  - 如果意向锁是行锁，则需要遍历每一行数据去确认
  - 如果意向锁是表锁，则只需要判断一次即可知道有没有数据行被锁定，提升性能

#### 意向共享锁

#### 意向排他锁

#### 临键锁

- 可以理解为一种特殊的间隙锁 可以解决幻读的问题，每个数据行上的非唯一索引上都会存在一把临键锁。当某个事务持有该数据行的临键锁时，会锁住一段左开右闭区间的数据。
- InnoDB 中行级锁是基于索引实现的，临键锁只与非唯一索引有关，在唯一索引（包括主键列）列上不存在临建锁

#### 记录锁

## CAS

- 原子性问题 lock

### ABA 问题

- 引入版本号 来解决该问题
- A -> B 当存在线程 A 想要修改数据从 A 变成 B，在这个过程中数据是发生了变化，但仍然可以操作成功
- A -> C -> A 线程 B 在该过程中将数据 A 变成 C 再改变为 A

### synchronized

synchronized 单线程时采用偏向锁 线程过多时采用轻量级锁 最后才会采用重量级锁

### 超卖问题

- 在单进程系统中，可以利用 synchronized 或者其他锁来解决该问题 保证只有一个线程能操作数据
- 但在分布式系统中，以上方法是不适用的，可以采用分布式锁来解决该问题
- redis 实现分布式锁 setnx 在服务器宕机时，会出现锁无法释放的问题，出现死锁
  - 通过设置过期时间，要保证加锁和设置过期时间是原子性的
  - 锁的过期时间设置不合理的情况下，可能存在逻辑处理还未完成，锁出现过期，同时新添加的锁被其他线程删除，出现锁没有添加，通过添加 UUID，让系统自己删除自己添加的锁
  - 通过设置锁续命，延期操作，保证不会出现锁过期了，任务还没执行完成
  - 判断 UUID 是否与添加锁的用户的 UUID 是否一致，但是可能出现判断一致完到删除 key 时出现卡顿，删除他人设置的锁，要保证原子性操作
- 利用 redisson 来实现分布式锁
- redis lua 脚本是原子性操作的，不会被中途打断.
- 分布式锁在主从节点切换的时候出现锁丢失问题 redlock 超过半数 redis 节点加锁成功才算加锁成功
- redis 采用奇数个节点，5 台机器能保证，不需要 6 台机器，多一台机器耗费性能
- zookeeper 不存在主从节点切换锁丢失的问题 它能保证含有锁的从节点升级为主节点 redis 实现分布式锁的性能更高一些
- 锁的优化
  - 降低锁的粒度

#### 优化

##### 如何定位慢查询

- 页面加载过慢，接口压测响应时间过长（超过 1s）
  - mysql 自带的慢日志查询 慢日志记录了所有执行时间超过指定参数的所有 SQL 语句的日志，如果要开启慢查询日志，需要在 MYSQL 的配置文件中进行配置 slow_query_log long_query_time
  - 开源工具进行查询

##### SQL 语句执行很慢，如何进行优化

- 聚合查询 多表查询 优化 SQL 语句
- 表数据量过大查询
  - 利用 explain desc 命令获取 mysql 如何执行 select 语句的信息
  - possible_key 当前 sql 可能会使用到的索引
  - key 当前 sql 实际命中的索引 结合 key_len 一起检查是否命中了索引，索引本身是否存在失效的情况
  - key_len 索引占用的大小
  - extra 额外的优化建议 是否出现了回表 如果出现了 可以尝试添加索引或修改返回字段来进行修复
  - type sql 连接的类型 const 根据主键查询 eq_ref 主键索引查询或者唯一索引查询 ref 索引查询 range 范围查询 index 索引树扫描(全索引扫描) all 不走索引 全盘扫描数据
- 深度分页查询

#### 索引

- 帮助 Mysql 高效获取数据的数据结构，在数据之外，数据库系统还存在满足特定查找算法的数据结构(B+树)，这些数据结构以某种方式引用(指向)数据，这样就可以在这些数据结构上实现高效查找的算法
- 索引的底层数据结构
  - 红黑树本质是二叉树 数据量多大时，树的高度会特别的高
  - B 树是一个多叉树查找树 每个节点有多个分支即多叉
  - B+树 是 B 树的优化 非叶子节点只存储指针不存储数据 只在叶子节点存储数据，非叶子节点进行导航 叶子节点利用双向指针进行连接起来 双向链表
  - 相较于 B 树 磁盘读写代价 B+树更低 查询效率更加稳定 B+树便于扫库和区间查询

##### 聚簇索引 非聚簇索引

- 聚簇索引
  - 将数据存储与索引放到了一块 索引结构的叶子节点保存了行数据 必须存在而且只有一个
  - 选择规则：
    - 如果存在主键 主键索引就是聚簇索引
    - 如果不存在主键，将使用第一个唯一索引作为聚簇索引
    - 如果表种没有主键也没有唯一适合的索引，InnoDB 会自动生成一个 rowId 作为隐藏的聚簇索引
- 非聚簇索引
  - 将数据与索引分开存储，索引结构的叶子节点关联的是对应的主键 可以存在多个
- 回表查询
  - 通过二级索引找到对应的主键值，到聚簇索引中查找整行数据，这个过程就是回表

##### 覆盖索引
- 查询使用了索引，并且需要返回的列，在索引中已经全部能够找到，不需要进行回表操作
- 使用id查询，直接找聚簇索引查询，一次索引扫描，直接返回数据，性能高
- 如果返回的列中没有创建索引，有可能会触发回表查询，尽量避免使用select *
- Mysql超大分页怎么解决  limit分页查询 需要对数据进行排序，效率低
  - 在数据量比较大的时候，如果进行limit分页查询，在查询时，越往后，分页查询效率越低
  - 通过创建覆盖索引能够比较好地提高性能，可以通过覆盖索引加子查询形式进行优化

##### 索引创建的原则
- 针对数据量比较大，且查询比较频繁的表建立索引 单表超过10万数据(增加用户体验)
- 针对于常作为查询条件，排序，分组操作的字段建立索引
- 尽量选择区分度高的列作为索引，尽量建议唯一索引，区分度高，使用索引的效率越高
- 如果是字符串类型的字段，字段长度较长，可以针对字段的特点，建立前缀索引
- 尽量使用联合索引，减少单列索引，查询时，联合索引很多时候可以走覆盖索引，节省存储空间，避免回表，提高查询效率
- 要控制索引的数量，索引越多，维护索引结构的代价业界越大，影响增删改的效率
- 如果索引列不能存储NULL值，请在创建表时使用NOT NULL 约束它，当优化器指导每列是否包含NULL值时，可以更好确定哪个索引最有效用于查询

##### 索引失效
- 违反最左前缀法则 最左前缀法则指的是查询从索引的最左前列开始，并且不跳过索引索引中的列
- 范围查询右边的列，不能使用索引
- 不要在索引列上进行运算操作，索引将会失效
- 字符串不加单引号，造成索引失效   没有对字符串加单引号，mysql查询优化器会自动的进行类型转换，造成索引失效
- 模糊查询可能造成索引失效  仅仅是尾部模糊匹配，索引不会失效  头部模糊查询会造成索引失效

##### sql优化
- 表的设计优化
  - 参考阿里开发手册
  - 设置合适的数值
  - 设置合适的字符串类型 char定长效率高
- 索引优化 参考索引创建原则和索引失效
- sql语句优化
  - select务必指明字段的名称
  - 避免索引失效的写法
  - 尽量用union all 代替union union会多过滤一次，效率低
  - 避免在where子句中对字段进行表达式操作
  - 尽量使用inner join 不用left join和right join 内连接会对两个表进行优化 优先把小表放到外边，大表放在里面   left join和right join不会重新调整顺序
- 主从复制 读写分离
  - 主库负责写操作 从库负责读操作   不让数据的写入 影响读操作 同时保证主从复制
- 分库分表
  
#### Mysql事务
##### 事务特性
  - ACID
    - 原子性
    - 一致性
    - 隔离性
    - 持久性
##### 并发事务带来了哪些问题 Mysql隔离级别
- 脏读：一个事务读取到了另外一个事务还没有提交的数据
- 不可重复读：一个事务先后读取同一条记录，但两次读取的数据不同吗，称之为不可重复读
- 幻读：一个事务按照条件查询数据时，没有对应的数据行，但是在插入数据时，又发现这行数据已经存在，好像出现了"幻影"
- 隔离级别：
  - 读未提交
  - 读已提交
  - 可重复读
  - 串行化
  
#### 日志
- 数据页：InnoDB存储引擎磁盘管理的最小单元，页中存储的是行数据
- 缓冲池：主内存中的一个区域，里面可以缓存磁盘上经常操作的真实数据，在执行增删改查操作时，先操作缓冲池中的数据（若缓冲池没有数据，先从磁盘加载并缓存），以一定频率刷新到磁盘，减少磁盘IO，加快处理速度
##### undo log
- 回滚日志 用于记录数据被修改之前的信息  提供回滚和MVCC  它是一种逻辑日志
- 保证事务的原子性和一致性
##### redo log
- 重做日志，记录的是事务提交时数据页的物理修改，用来实现事务的持久性 服务宕机可用来同步数据 保证事务的持久性
- 重做日志缓冲 重做日志文件  前者在内存中，后者在磁盘中 当事务提交之后会把所有修改信息都缓存到该日志文件中，用于在刷新脏页到磁盘，发生错误时，进行数据恢复使用

#### MVCC(重点)
- 多版本并发控制，维护一个数据的多个版本，是的读写操作没有冲突
- 主要依赖于隐藏字段   undo log 和 readView
- 隐藏字段
- undo log
  - 不同事务或者相同事务对同一条记录进行修改，会导致该记录的undo log 生成一条记录版本链表，链表的头部时最新的旧纪录，链表的尾部时最早的旧纪录
- readView
  - 快照读 SQL执行时MVCC提取数据的依据，记录并维护系统当前活跃的事务(未提交)ID
  - 当前读：记录的最新版本，读取时还要保证其他并发事务不能修改当前记录，会对读取的记录进行加锁
  - 快照读：简答的select(不加锁) 读取的时记录数据的可见版本，有可能是历史数据，不加锁，是非阻塞读
    - 读已提交：每次select 都生成一个快照读
    - 可重复读：开启事务后第一个select语句才是快照读的地方

#### 主从同步
- 核心就是二进制文件
- bin log  记录了所有的DDL(数据定义语言)语句和DML(数据操纵语言)语句，但不包括数据查询(SELECT SHOW)语句
- master主库在事务提交时，会把数据变更记录在二进制日志文件bin log中
- 从库读取主库的二进制日志文件bin log，写入到从库的中继日志 realy log
- slave从库重做中继日志中的事件，将改变反映他自己的数据

#### 分库分表
- 时机
  - 业务数据主键增多 单表数据量达 1000w 或20G
  - 优化已经解决不了性能问题（主从读写分离、查询索引）
  - IO瓶颈（磁盘IO 网络IO） CPU瓶颈（聚合查询 连接数太多）
- 垂直分库
  - 以表为依据，根据业务将不同的表存储到不同的库中
  - 按业务对数据分级管理，维护，监控，扩展
  - 高并发下提升性能
- 垂直分表 
  - 以字段为依据，根据字段属性将不同字段拆分到不同的表中
  - 冷热数据分离
  - 减少IO过度争抢，两表互不影响
- 水平分库
  - 将一个库的数据拆分到多个库中
  - 解决了单库大数量，高并发的性能瓶颈问题
  - 提高了系统的稳定性和可用性
- 水平分表
  - 将一个表的数据拆分到多个表中（可以在同一个库内）
  - 优化单一表数据量过大而产生的性能问题
  - 避免IO争抢并减少锁表的几率



