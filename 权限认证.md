### 认证授权
- 认证：你是谁 验证您的身份的凭证 通过该凭证，系统得以指导你就是你，系统存在该用户，被称为用户/身份验证
- 授权：发生在认证之后， 主要和赃官访问系统的权限，比如有些特定资源只有具有特定权限的人才能访问比如admin 有些系统资源操作比如删除、添加、更新只有特定的人才具有
- RBAC 基于角色的权限访问控制 用户、角色和权限之间相互关联的授权的方式 在RBAC中，权限和角色相关联，用户通过成为适当角色的成员而得到这些角色的权限，系统一般都会选择使用RBAC模型来做权限控制
- Cookie
  - 用来跟踪浏览器用户身份的会话方式 它是一种存储在用户本地终端上的 存放在客户端 保存用户信息
  - 使用cookie保存SessionID 或者token 向后端发送请求时 带上cookie 后端就能获取到session或者token了 
  - spring中使用@CookieValue注解可以获取特定的cookie值 或者通过HttpServletRequest.getCookies() 来获取所有的Cookie
- Session
  - 通过服务端记录用户的状态 相对于cookie session是安全性更高一些， 使用cookie时不要添加敏感信息到cookie中
  - **使用session-cookie进行身份验证**
    - 用户成功登陆系统，然后给客户端返回具有SessionId的cookie 
    - 当用户向后端发送请求时会把SessionId带上，后端与存储在内存中或者数据库中的Session信息进行比较，以验证用户的身份，返回给用户客户端响应信息的时候会附带当前用户的状态
  - 依赖session的关键业务一定要保障客户端开启了cookie，**如果客户端禁用了cookie session就无法正常工作  也可以将sessionId放在请求的url里面，这种方案可行但是安全和体验感将大大降低，也可以将sessionId进一步加密传输到后端**
  - 注意session的过期时间
  - **多服务器节点下Session-cookie方案如何做**
    - 当存在多台服务器节点的时候，一般使用nginx来实现负载均衡，将用户的请求转发到对应的服务器上，用户前后两次访问请求可能会被转发到不同的服务器上，但是服务器保存的用户session信息并没有统一，导致用户身份信息失效
    - 解决方案：
      - 保证同一个用户的请求通过特定的哈希算法分配给同一个服务器进行处理，但是当服务器宕机了，该服务器对应的用户都将无法访问
      - 每一个服务器保存的session信息都是互相同步的，一个服务器保存了全量的session信息，每当session信息发生变化，每一个服务器都将进行同步，信息量大
      - **单独使用一个所有服务器都能访问到的数据节点(比如缓存)来存放session信息，为了保证高可用，数据节点尽量要避免是单节点**
- Cookie无法防止CSRF攻击，token可以防止，token一般会存放在localStorage(浏览器本地存储)中，非法的请求是不会携带token的，这个请求将是违法的。但是他们都将不能避免跨站脚本攻击

### SSO
- 单点登陆 用户登陆多个子系统的其中一个就有权访问与其相关的其他系统。
- 优点
  - 用户角度：用户能够做到以此登陆多次使用，无需记录多套用户名和密码，省心
  - 系统管理员角度：管理员只需维护好一个统一的账号就可以了，方便
  - 新系统开发角度：新系统开发时秩序直接对接统一的账号中心即可，简化开发流程，省时
- 用户登陆状态的存储与校验
  - 常见的Web框架对于session的实现都是生成一个SessionId存储在浏览器Cookie中，然后将session内容存储在服务器端内存中
  - 用户登陆成功之后，生成AuthToken交给客户端保存，如果是浏览器就保存在cookie中，如果是手机就保存在App本地缓存中
  - 用户在浏览需要登陆的界面是，客户端将AuthToken提交给SSO服务校验登陆状态/获取用户登陆信息
  - 对于登陆信息的存储，建议采用Redis，使用redis集群来存储登陆信息，既可以保证高可用，又可以线性扩充，同时也可以让SSO服务满足负载均衡/可伸缩的需求
  - 解决跨越的核心思路：
    - 登陆完成之后通过回调的方式，将AuthToken传递给主域名之外的站点，该站点自行将AuthToken保存在当前域下的cookie中
    - 登出完成之后通过回调的方式，调用非主域名站点的登出页面，完成设置Cookie中的AuthToken过期的操作
  - | 对象 | 说明 | 
    | :-----| ----: | 
    | AuthToken | 直接使用UUID/GUID即可，如果有验证AuthToken合法性需求，可以将UserName+时间戳加密生成，服务器端解密之后验证合法性 |
    | 登陆信息 |通常是将UserId UserName缓存起来 | 

### JWT
- 一种基于token的认证授权机制 它自身包含了身份验证所需要的所有信息，服务器不需要存储session信息，增加了系统的可用性和伸缩性，大大减轻了服务端的压力
- 本质上就是一组字符串，通过. 切分成三个为Base64编码的部分
  - Header: 描述JWT的元数据，定义了生成签名的算法以及Token的类型 
  - Payload: 用来存放实际需要传递的数据，包含了Claims声明  分为注册申明、公有申明、私有申明，**该部分是默认不加密的，不要将私密信息存放在Payload中**
  - Signature: 服务器通过Payload、Header和一个密钥Secret 使用Header指定的签名算法生成
    - **使用到的密钥是存放在服务端的，一定不能泄露出去**
- 如何基于JWT进行身份验证
  - 服务器通过Payload、 Header和Secret创建JWT并将JWT发送给客户端。客户端接收到JWT之后，会将其保存在Cookie或者localStorage里面，以后客户端发送的请求都将携带这个令牌，用户以后每次向后端发送请求都将在Header中携带这个JWT，服务器检查该JWT并从中获取用户相关信息
  - **建议将JWT存放在localStorage中，放在cookie中会有CSRF风险**
  - 请求服务端并携带JWT的常见做法是将其放在HTTP Header的Authorization字段中
- 如何防止JWT被篡改
  - 服务端拿到JWT会解析出Payload、 Header和Signature，然后根据Payload、 Header和密钥生成一个新的Signature，然后根据之前的进行对比
  - JWT的安全核心在于签名，签名安全的核心在于密钥
- 如何加强JWT的安全性
  - 使用安全系数高的加密算法
  - jwt存放在localStorage
  - 隐私信息不要存放在Payload中
  - 密钥保管好
  - 保证jwt是有失效性的
  - 使用开源库，没必要造轮子
- JWT身份验证的优缺点分析
  - 无状态 自身包含了身份验证所需要的所有信息 服务器不需要存储session信息
  - 有效避免了CSRF攻击 使用jwt进行身份验证不需要依赖Cookie，可以避免CSRF攻击  常见的XSS攻击避免在spring中一般通过创建XSS过滤器来实现
  - 适用于移动端用户 
  - 单点登陆友好
  - jwt一旦派发出去，后端不增加其他逻辑的话，它在失效之前都是有效的
    - 将jwt存储在内存数据库中
    - 黑名单机制
    - 修改密钥 想让某个jwt失效，直接修改对应用户的密钥即可 但是危害更大
    - 保持令牌的有效期限短并经常轮换
  - JWT续签问题
    - 类似于session认证中的做法
    - 每次请求都返回新的JWT
    - JWT有效期设置到半夜
    - 用户登陆返回两个JWT
    - 使用普通的token结合redis来做身份认证也是可以的


### 常见的加密算法
- 一种用数学方法对数据及逆行变换的技术，目的就是保护数据的安全，防止被未经授权的人读取或修改。
- 分类
  - 对称加密算法  用来保护数据的安全性和保密性
    - 对称加密算法是指加密和解密使用同一个密钥的算法，也叫共享密钥加密算法
    - DES使用64位的密钥和64位的明文进行加密
    - 3DES使用2个或者3个56位的密钥对数据进行三次加密，相当于是对每个数据块应用三次DES的对称加密算法
    - AES使用128位 192位或者256位的密钥对数据进行加密或解密，密钥越长，安全性越高
  - 非对称加密算法 用来实现数据的安全传输和身份认证
    - 指加密和解密使用不同的密钥的算法，也叫做公开密钥加密算法，这两个密钥互不相同，一个为公钥，一个为私钥，公钥可以公开，私钥要保密
    - 如果用公钥加密数据，只能用对应的私钥解密，如果用私钥加密数据，只能用对应的公钥解密，这样实现数据的安全传输和身份认真
    - RSA 基于大数分解的困难性的非对称加密算法，需要选择两个大素数作为私钥的一部分，然后计算出他们的乘积作为公钥的一部分
    - DSA 基于离散对数的困难行的非对称加密算法，需要选择一个素数q和一个q的倍数p作为私钥的一部分，然后计算一个模p的原根g和一个模q的整数y作为公钥的一部分
    - ECC
  - 哈希算法
    - 也称作哈希函数、散列函数或者摘要算法 它的作用是对任意长度的数据生成一个固定长度的唯一标识，也叫做哈希值、散列值或者消息摘要
    - 哈希值的作用是可以用来验证数据的完整性和一致性
    - 特点
      - 不能从哈希值还原出原始数据 不可逆的
      - 原始数据的任何改变都会导致哈希值的巨大变化
    - 分类
      - MD 消息摘要算法 MD5  不再推荐被使用 存在被破解的风险
      - SHA 安全哈希算法 SHA-1 SHA-256
        - 相比于MD5算法，SHA-256算法更强，SHA-256算法的哈希值长度为256为，MD5算法的哈希值为128位，提高了攻击者暴力破解或者彩虹表攻击的难度   同时SHA算法采用了更复杂的运算过程和更多的轮次，使得攻击者难以通过与计算或巧合找到碰撞，具有更强的碰撞抗性
      - MAC 消息认证码算法
      - 国密算法 SM3  密码哈希算法 Bcrypt
        - Bcrypt算法专门为密码加密而设计，安全性更高 采用了salt和cost两种机制，有效防止彩虹表攻击和暴力破解攻击
        - salt是一个随机生成的字符串，用于和密码混合，增加密码的复杂度和唯一性，cost是一个数值参数，用于控制bcrypt算法的迭代次数，增加密码哈希的计算时间和资源消耗。可以根据实际情况进行调整加密的复杂度，可以设置不同的cost值和salt值
    - **盐在密码学中，指通过在密码任意固定位置插入特定的字符串，让哈希后的结果和使用原始密码的哈希结果不相符，这个过程称之为加盐**

### 敏感词过滤方案
- https://github.com/hooj0/sensitive-words-filter
- 系统需要对用户输入的文本进行敏感词过滤如色情、政治、暴力相关的词汇
- **Trie树算法**
  - leetcode208题
  - 字典树、单词查找树， 哈希树的一种变种，通常被用于字符串匹配，用来解决一组字符串集合中快速查找某个字符串的问题
- DFA算法
  - 确定有穷自动机    NFA 不确定有穷自动机
- **数据脱敏**
  - 根据特定规则对敏感信息数据进行变形，比如报手机号、身份证号某些位数使用*来代替

### 定时任务
- 单机定时任务
  - Timer 内部使用一个叫做TaskQueue类存放定时任务，它是一个基于最小堆实现的优先级队列，TaskQueue会按照任务距离下一次执行时间的大小将任务排序，保证在堆顶的任务最先执行。这样在执行需要执行的任务时，每次只需要取出堆顶的任务运行即可 **缺陷是任务只能串行执行，一个任务执行时间过长会影响别的任务，发生异常直接停止**
  - ScheduledExecutorService 支持多线程执行定时任务并且功能更强大，这是一个接口，有多个实现类
  - Spring Taks 直接通过Spring提供的@Scheduled注解定义定时任务，自带的定时调度只支持单机，提供的功能比较单一
  - 时间轮：简单来说就是一个环形的队列，底层一般基于数组实现，队列中的每一个元素都可以存放一个定时任务列表 时间轮中的每个时间格代表了时间轮的基本时间跨度或者时间精度，加入时间一秒走一个时间格的话，那么这个时间轮的最高精度就是1秒 **时间轮比较适合任务数量比较多的定时任务场景，任务写入和执行的时间复杂度都是O(1)**
- 分布式定时任务技术选型
  - 涉及的角色
    - 任务：首先可你的那个是要执行的任务，这个任务就是具体的业务逻辑比如定时发送文章
    - 调度器：其次就是调度中心，主要负责任务管理，会分配任务给执行器
    - 执行器：接受调度器分派的任务并执行
  - Quartz
  - Elastic-Job
  - XXL-JOB
  - PowerJob

### java实现用户任务排队

### Web实时消息推送详解

## 分布式
### 分布式ID
- 当数据分布在不用数据库上，数据库自增主键已经没办法满足生成的主键唯一了，需要为不同的数据节点生成全局唯一主键
- 满足的要求
  - 全局唯一: ID的全局唯一性肯定要满足
  - 高性能
  - 高可用
  - 方便易用
  - 安全
  - 有序递增
  - 有具体的业务含义
  - 独立部署
- 解决方案
  - 数据库
    - 数据库主键自增 每次获取ID都要访问一次数据库，ID需求比较大的时候，不太合适
    - 数据库号段模式 批量获取，然后存在内存中，需要用到的时候，直接从内存里面拿ID数据 相比于数据库自增主键的方式，数据库的号段模式对于数据库的访问次数更少，数据库压力更小
  - 采用NOSQL 例如redis 通过incr命令实现对id原子顺序递增
    - 优点： 性能不错并且生成的ID是有序递增的
    - 缺点： 和数据库主键自增方案缺点类似
  - 通过算法进行实现
    - UUID  jdk自带实现了UUID  UUID可以保证唯一性，其生成规则包括MAC地址、时间戳、名字空间、随机或者伪随机数、时序等元素，计算机基于这些规则生成的UUID是肯定不会重复的，生成速度快，简单易用
      - UUID作为MYSQL的主键不太合适 UUID消耗的存储空间比较大，数据库主键尽量越短越好 UUID是无序的，InnoDB引擎下，数据库主键的无序性会严重影响数据库性能
    - **snowflake 雪花算法  生成的ID有序递增，比较灵活 生成速度比较快**
      - 雪花算法生成的id是由64位的二进制数字组成，主要分为了以下几个部分
      - 第0位 符号位
      - 第1-41位，一共41位，表示时间戳
      - 第42-52位，一共10位，前五位表示机房ID 后五位表示机器ID 可以区分不同集群/机房的节点
      - 第53-64位 一共12位 表示序列号 序列号为自增值 代表单台机器每毫秒能够产生的最大唯一ID数 
  
### 分布式锁
- 在多线程环境中，如果多个线程同时访问共享资源（例如商品库存、外卖订单），会发生数据竞争，可能会导致出现脏数据或者系统问题，威胁到程序的正常运行
- 为了保证共享资源被安全地访问，我们需要使用互斥操作对共享资源进行保护，即同一时刻只允许一个线程访问共享资源，其他线程需要等待当前线程释放后才能访问，这样可以避免数据竞争和脏数据问题，保证程序的正确性和稳定性
- **一般实现共享资源的互斥访问，通用的方案是悲观锁**
- 对于**单机多线程**来说，java中通常使用ReetrantLock类 synchronized关键字这种自带的本地锁来控制一个JVM进程内的多个线程对本地共享资源的访问
- 对于**分布式系统**，不同的服务/客户端通常运行在独立的JVM进程上，多个JVM进程共享同一份本地资源，使用本地锁没办法实现资源的互斥访问。
  - 满足的条件
    - 互斥：任意时刻，锁只能被一个线程所占有
    - 高可用：当一个锁服务出现问题，能够自动切换到另外一个锁服务，同时能保证锁最终一定会被释放，不会影响其他线程对共享资源的访问，**通过超时机制来实现**
    - 可重入：一个节点获取了锁之后，还可以再次获取锁
  - 实现方案
    - 基于关系型数据库比如Mysql实现分布式锁  一般通过唯一索引或者排他锁实现，该方法性能差，不具备锁失效机制
    - 基于分布式协调服务Zookeeper实现分布式锁
      - **redis实现分布式锁性能高，zookeeper实现分布式锁可靠性高**
      - 基于临时顺序节点和事件监听器来实现  如果客户端发生异常导致没来得及释放锁，**会话失效节点也会自动被删除，不会发生死锁的问题**
      - zookeeper的节点类型
        - 持久节点：一旦创建就一直存在即使zookeeper集群宕机，直到将其删除
        - 临时节点: 临时节点的生命收起是与客户端会话绑定的，会话消失则节点消失。并且临时节点只能做叶子节点，不能创建子节点
        - 持久顺序节点：除了具有持久节点的特性之外，子节点的名称还具有顺序性
        - 临时顺序节点：除了具有临时节点的特性之外，子节点的名称还具有顺序性
        - 假设**不使用顺序节点的话，所有尝试获取锁的客户端都会对持有锁的子节点加监听器，当该锁被释放之后，会造成所有尝试获取锁的客户端来争夺锁，这样对性能不好**。**使用顺序节点之后，只需要监听前一个节点就好了**
    - 基于分布式键值存储系统比如Redis实现分布式锁
      - redis中setnx命令可以实现互斥 如果key不存在才会设置key的值，key已经存在则什么都不做 同时**使用lua脚本保证操作的原子性**，redis在执行lua脚本可以以原子性的方式执行，保证所释放操作的原子性
      - 当遇到一些问题比如释放锁的逻辑突然挂掉，可能导致锁无法被释放，进而造成共享资源无法在被其他线程/进程访问，此时可以给key设置一个过期时间，一定**要保证设置指定key的值和过期时间是一个原子操作**
      - 如果操作共享资源的时间大于过期时间，会出现锁提前过期的问题，进而导致分布式锁直接失效，可以**实现锁的优雅续期**
      - redisson的分布式锁自带自动续期的机制，其提供了一个专门**用来监控和续期锁的看门狗**，如果操作共享资源的线程还没有执行完成的话，看门狗会不断延长锁的过期时间，进而保证锁不会因超时而被释放 默认情况下，每过10秒，看门狗就会执行续期操作，将锁的超时时间设置为30秒，看门狗续期前也会先判断是否需要执行续期操作，需要才会执行续期，否则取消续期操作。**只有未指定锁超时时间，才会使用到看门狗的自动续期机制**
      - 可重入锁：一个线程中可以多次获取同一把锁，比如一个线程在执行一个带锁的方法，该方法中又调用了另一个需要相同锁的方法，则该线程可以直接执行调用的方法即可重入，而无需重新获得锁 可重入锁的实现核心思路是**线程在获取锁的时候判断是否为自己的锁，如果是的话，就不需要再重新获取锁了。我们可以为每个锁关联一个可重入计数器和一个占有它的线程，当可重入计数器大于0时，则锁被占有，需要判断占有该所的线程和请求获取锁的线程是否为同一个**。
      - redis解决集群情况下分布式锁的可靠性，采用红锁，让客户端向redis集群中的多个独立的redis实例以此请求申请加锁，如果客户端能够和半数以上的实例成功的完成加锁操作，那么可以任务，客户端成功获取分布式锁，否则加锁失败。**实现复杂且性能差**


### CDN
- 内容分发网络 CDN就是将静态资源分发到多个不同的地方以实现就近访问，进而加快静态资源的访问速度，减轻服务器以及带宽的负担
- 全站加速 可以同时加速静态和动态资源
- **同一个服务在多个不同的地方备份多份是为了实现系统的高可用而不是就近访问**
- 回源：当CDN节点上没有用户请求的资源或该资源的缓存已经过期，CDN节点需要从原始服务器获取最新的资源内容，这个过程就是回源。当用户请求发生回源的话，会导致该请求的响应速度比未使用CDN还慢，相比于未使用CDN还多了一层CDN的调用流程
- 预热：在CDN上提前将内容缓存到CDN节点上，这样当用户在请求这些资源时，能够快速地从最近的CDN节点获取到而不需要回源，进而减少了对源站的访问压力，提高了访问速度
- 为了防止静态资源被盗用，可以利用referer防盗链和时间戳防盗链

### 负载均衡
- 将用户请求分摊到不同的服务器上处理，以提高系统整体的并发处理能力以及可靠性，它是一种比较常用且实施起来较为简单的提高系统并发能力和可靠性的手段
- 服务端负载均衡
  - 硬件负载均衡通过专门的硬件设备来实现负载均衡
  - 软件负载均衡通常使用nginx HAproxy来实现
    - 四层负载均衡： 工作在OSI模型的第四层也就是传输层，主要协议为TCP/UDP 负载均衡器在这一层能够看到数据包里的源端口以及目的端口地址，会基于这些信息通过一定的负载均衡算法将数据包转发到后端真实服务器。**四层负载均衡的核心就是IP+端口层面的负载均衡，不涉及具体的报文内容**
    - 七层负载均衡： 工作在OSI模型的第七层也就是应用层，主要协议为HTTP，它会读取保温的数据部分，比如HTTP部分的报文，根据读取到的数据内容如URL Cookie做出对应的负载均衡决策。**七层负载均衡器的核心是报文内容层面的负载均衡，执行第七层负载均衡的设备通常被称为反向代理服务器**
    - 四层负载均衡性能更强，七层负载均衡功能更强
- 客户端负载均衡
  - **主要应用于系统内部的不同的服务之间，可以使用现成的负载均衡组件来实现  Netflix Ribbon和Spring Clound Load Balancer**
  - 在客户端负载均衡中，客户端会自己维护一份服务器的地址列表，发送请求之前，客户端会根据对应的负载均衡算法来选择某一台服务器处理请求。 客户端负载均衡器和服务运行在同一个进程或者java程序里，不存在额外的网络开销
- 常见的负载均衡算法
  - 随机法：最简单粗暴的负载均衡算法 如果没有配置权重的话，所有的服务器被访问到的概率是相同的。如果配置权重的话，权重越高的服务器被访问的概率越大。未加权重的随机算法适用于服务器性能相近的集群，每台服务器承载相同的负载。加权随机算法适合服务器性能不同的集群，保证请求分配合理化
  - 轮询法：挨个轮询服务器处理，同时也可以设置权重。没有配置权重的话，每个请求按时间顺序注意分配到不同的服务器处理。如果配置权重的话，权重越高的服务器被访问的次数就越多。
  - 一致性哈希算法：**相同参数的请求总是转发到同一台服务器处理，比如同一个IP的请求**
  - 最小连接法： **当有新的连接出现时，遍历服务器节点列表并选取其中活动连接数最小的一台服务器来响应当前请求**。活动连接数可以理解为当前正在处理的请求数。**最小连接法可以尽可能最大化地使请求分配更加合理化**，提高服务器的利用率。该方法需要监控每一台服务器处理的请求连接数
- 七层负载均衡可以怎么做？
  - DNS解析
    - 在DNS服务器中为同一个主机记录配置多个IP地址，这些IP地址对应不同的服务器。当用户请求域名的时候，DNS服务器采用轮询算法返回IP地址，实现轮询负载均衡 DNS解析也支持IP地址配置权重
  - **反向代理**
    - 客户端将请求发送到反向代理服务器，由反向代理服务器去选择目标服务器，获取数据后返回给客户端。对外暴露的使反向代理服务器地址，隐藏了真实服务器IP地址。反向代理“代理”的使目标服务器，这个过程对客户端是透明的，nginx就是这种反向代理来实现负载均衡



### 数据库读写分离 分库分表
#### 读写分离
- 读写分离主要是为了将对数据库的读写操作分散到不同的数据库节点上。这样的话，就能够小幅提升写性能，大幅提升读写能。一般情况下，会选择一台主数据库负责写数据，其他的从数据库负责读数据。主库和从库之间会进行数据同步，以保证库中数据的准确性。
- 读写分离对于提升数据库的并发非常有效，但是也导致了主库和从库的数据存在延迟，主库数据同步到从库是需要时间的，这个时间差导致了主库和从库的数据不一致性问题，也就是主从同步延迟。
  - 解决方案
    - 强制将读请求路由到主库处理  可以将那些必须获取最新数据的读请求都交给主库处理
    - 延迟读取
- 实现读写分离的步骤  **可以在应用和数据之间加一个代理层，应用程序所有的数据请求都交给代理层处理，代理层负责分离读写请求，将他们路由到对应的数据库中**或者引入第三方组件实现
  - 1.部署多态数据库，选择其中的一台作为主数据库，其他的一台或者多台作为从数据库
  - 2.保证主从数据库之间的数据是实时同步的，也就是主从复制
  - 3.系统将写请求交给主数据库处理，将读请求交给从数据库处理
- **主从复制的原理**
  - Mysql的bin log 二进制日志文件 主要记录了Mysql数据库中数据的所有变化（数据库执行的所有DDL和DML语句）  binlog可以实现主从复制之外，还能帮助我们实现数据恢复
  - 1.主库将数据库中的数据变化写入到binlog
  - 2.从库连接主库
  - 3.从库会创建一个I/O线程向主库请求更新新的binlog
  - 4.主库会创建一个binlog dump线程来发送binlog，从库的I/O线程负责接收
  - 5.从库的I/O线程将接收的binlog，写入到relay log中
  - 6.从库的sql线程读取relay log 同步数据到本地（也就是再执行一遍sql语句）

#### 分库分表
- 读写分离主要应对的是数据库读并发问题，没有解决数据库存储问题。使用分库分表能够解决Mysql的存储压力
- 分库
  - 将数据库中的数据分散到不同的数据库上，可以垂直分库，也可以水平分库
  - 垂直分库：把单一数据库按照业务进行划分，不同的业务使用不同的数据库，进而将一个数据库的压力分担到多个数据库
  - 水平分库：把同一个表按一定规则拆分到不同的数据库中，每个库可以位于不同的服务器上，这样就实现了水平扩展，解决了单表的存储和性能瓶颈的问题
- 分表
  - 对单表的数据进行拆分，也可以分为垂直拆分，也可以水平拆分
  - 垂直分表：对数据表列的拆分，把一张列比较多的表拆分为多张表
  - 水平分表：对数据表行的拆分，把一张行比较多的表拆分成多张表，可以解决单一表数据量过大的问题  水平拆分只能解决单表数据量大的问题，为了提升性能，通常将拆分后的多张表放在不同的数据库中，水平分表和水平分库通常同时出现
  - 以下几种情况考虑分库分表
    - 单表的数据到达千万级别以上，数据库读写速度非常缓慢
    - 应用的并发量太大
    - 数据库中的数据占用的空间越来越大，备份时间越来越长
- **分片算法**
  - 分片算法主要解决了数据被水平分片之后，数据该放在哪个表的问题
  - 哈希分片：求指定key的哈希，然后根据哈希值确定数据应被放置到哪个表中，哈希分片比较适合随机读写的场景，不太适合经常需要范围查询的场景
  - 范围分片：按照特性的范围区间来分配数据，例如时间区间、ID区间。范围分片适合需要范围查询的场景，不适合随机读写的场景。数据未被分散，容易出现热点数据的问题
  - 地理位置分片：根据地理位置来分配数据
  - 融合算法： 灵活组合多种分片算法，比如哈希分片和范围分片组合
- 分库分表带来的问题
  - 同一个数据库中的表分布在了不同的数据库中，导致无法使用join操作
  - 事务问题：单个操作设计了多个数据库，数据库自带的事务满足事务要求了
  - 分布式ID：数据分布在不同的数据库中，数据库的自增主键已经没有办法满足生成的主键唯一了。需要引入分布式Id解决该问题。
- 分库分表之后，数据如何实现迁移
  - 停机迁移
  - 双写方案  老库新库同时进行操作


## 消息队列
- 消息队列可以看作是一个存放消息的容器，当我们需要使用消息的时候，直接从容器中取出消息供自己使用。队列Queue是一种先进先出的数据结构后，所有消费消息也是按顺序来消费的
- 参与消息传递的双方称为生产者和消费者 **生产者负责发送消息，消费者负责处理消息**
- 使用消息队列可以**降低系统耦合性、实现任务异步、有效地进行流量削峰**，是分布式和微服务系统中重要1的组件
- 好处
  - 通过异步处理提高系统性能(减少响应所需时间)
    - 将用户请求数据存储到消息队列之后就立即返回结果，随后系统再对消息进行消费  使用消息队列进行异步处理之后，需要适当修改业务流程进行配合
  - 削峰/限流
    - 先将短时间高并发产生的事务消息存储在消息队列中，然后后端服务再慢慢根据自己的能力去消费这些消息，这样避免了直接把后端服务打跨掉
  - 降低系统耦合度
    - 生产者发送消息到消息队列中去，接收者处理消息。需要消费的系统直接去消息队列取消息进行消费即可而不需要和其他系统有耦合。
- **为了避免消息队列服务器宕机造成消息丢失，会将成功发送到消息队列的消息存储在消息队列服务器上，只有当消费者成功处理了消息才会从消息生产者服务器中删除消息。在消息队列服务器宕机之后，生产者服务器会选择分布式消息队列服务器集群中的其他服务器发布消息**
- 使用消息队列带来的问题
  - 系统可用性降低
  - 系统复杂性提高  需要保证消息没有被重复消费，处理消息丢失的情况，保证消息传递的顺序性
  - 一致性问题  消费者没有正确消费数据，就可能导致数据不一致性问题
### 实现分布式事务

### JMS AMQP RPC
- JMS java消息服务  JMS客户端可以通过JMS进行异步的消息传输
  - 两种消息模式
    - P2P 点对点模式
    - 发布订阅模式
- AMQP 一个提供统一消息服务的应用层标准高级消息队列协议 二进制应用层协议
- RPC 
  - 主要解决两个服务的远程通信问题，不需要了解底层网络的通信机制。通过RPC可以帮助我们调用远程计算机上的某个服务的方法，这个过程就像调用本地方法一样简单
  - RPC是双向直接网络通信，消息队列是单向引入中间载体的网络通讯
  - 消息队列需要把消息存储起来，RPC不需要
  - 通过RPC发出的调用一般会立即被处理，存放在消息队列中的消息并不一定会立即被处理


### Kafka 
- kafka是一个分布式流式处理平台
- 流平台的关键功能
  - 消息队列：发布和订阅消息
  - 容错的持久方式存储记录消息流 kafka会把消息持久化到磁盘中，有效避免丢失的风险
  - 流式处理平台
- **两大应用场景**
  - 消息队列：建立实时流数据管道，以可靠地在系统或应用程序之间获取数据
  - 数据处理：构建实时的流数据处理程序来转换或处理数据流
- **队列模型(早期的消息模型)**
  - 使用队列作为消息通信在台，满足生产者和消费者模式，一条消息只能被一个消费者使用，未被消费的消息在队列中保留直到被消费或超时。
  - 存在的问题：当需要将生产者产生的消息分发给多个消费者，并且每个消费者都能接收到完整的消息内容 队列模型就不好解决
- **发布订阅模式(kafka消息模型)**
  - 发布订阅模式使用主题作为消息通信载体，类似于广播模式，发布者发布一条消息，该消息通过主题传递给所有的订阅者，在一条消息广播之后才订阅的用户则是收不到消息的。发布订阅模式在功能层面是可以兼容队列模型的
- 概念
  - Producer 生产者 产生消息的一方
  - Consumer 消费者 消费消息的一方
  - Broker 代理 可以看作是一个独立的kafka实例 多个kafka broker 组成一个kafka cluster 
  - topic 主题 生产者将消息发送到特定的主题，消费者通过订阅特定的主题来消费消息
  - Partition 分区 一个Topic可以有多个partition 并且同一Topic下的Partition可以分布在不同的Broker上，一个Topic可以横跨多个Broker 
- **kafka的多副本机制，以及好处**
  - kafka为分区引入了多副本的机制。分区中的多个副本之间会有一个叫做Leader的家伙，其他副本称为follower。我们发送的消息会被发送到leader副本，然后follower才能从leader副本中拉取消息进行同步
  - 生产者与消费者只与leader副本进行交互。其他副本只是leader副本的拷贝，他们的存在只是为了保证消息存储的安全性。当leader发生故障时会从follower中选取出一个leader
  - kafka通过给特定的topic指定多个partition，而各个partition可以分布在不同的broker上，这样便能提供比较好的并发能力(负载均衡)
  - partition可以指定副本数，这也极大地提高了数据存储的安全性，提升了容灾能力，不过也就相应增加了所需要的存储空间
- **zookeeper在kafka中的作用**
  - Broker注册 在zookeeper中会有一个专门用来进行Broker服务器列表记录的节点。每个Broker在启动时，都回到zookeeper上进行注册，**即到/brokers/ids下创建属于自己的节点。每个broker上就会将自己的IP地址和端口等信息记录到该节点上去**
  - 在 Kafka 中，**同一个Topic 的消息会被分成多个分区并将其分布在多个 Broker 上，这些分区信息及与 Broker 的对应关系也都是由 Zookeeper 在维护**。比如我创建了一个名字为 my-topic 的主题并且它有两个分区，对应到 zookeeper 中会创建这些文件夹：/brokers/topics/my-topic/Partitions/0、/brokers/topics/my-topic/Partitions/1
  - **负载均衡**： 对于同一topic的不同partition，Kafka会尽力将这些partition分布到不同的Broker服务器上。当生产者产生消息后也会尽量投递到不同broker的partition上。当消费者消费时，zookeeper可以根据当前的partition数量以及consumer来实现动态负载均衡
- **kafka如何保证消息的消费顺序**
  - kafka中的partition是真正保存消息的地方。每次添加消息到partition的时候都会采用尾加法，**Kafka只能保证partition中的数据有序。消息在被追加到partition的时候会分片一个特定偏移量(offset)，kafka通过偏移量来保证消息在分区中的有序性**
  - 因此可以采用一个topic对应一个partition或者**发送消息时指定对应的key/partition来指定。同一个key的消息可以保证消息只发送到同一个partition**。
- **kafka如何保证消息的不丢失**
  - 生产者调用send方法之后，可以通过get方法获取调用结果，但是该方法将异步的操作变为了同步，**一般推荐添加回调函数，来获取执行的结果**。如果消息发送失败则重新发送
  - 推荐producer的**重试次数设置一个比较合理的值**，当出现网络问题之后能够自动重试消息发送，避免消息丢失。**同时设置合理的重试间隔**
  - **当消费者刚拿到消息准备进行真正消费的时候，突然挂掉了，消息时间上没有被消费，但是offset被自动提交了**。可以尝试手动关闭自动提交offset，每次在真正消费完消息之后再自己手动提交offset，**但是这也可能在刚好完成消息消费，消费者挂掉了，没有完成offset提交，存在重复消费消息的问题**
  - **kafka弄丢了消息**
    - 加入leader副本所在broker突然挂掉，那么就要从follwer副本重新选择一个leader，但是leader的数据还有一些没有被follower副本同步的话，就会造成消息丢失
    - 设置acks=all  只有所有ISR列表的副本全部接收到消息时，生产者才会接收到来自服务器的响应。acks=1默认值，代表消息被leader副本接手之后就算发送成功
    - 设置replication.factor>=3 保证leader副本能有follower副本同步消息，虽然造成了数据冗余，但是带来了数据的安全性
    - 设置min.insync.replicas>1 表示消息至少被写入到两个副本才算成功发送  replication.factor =  min.insync.replicas + 1
    - 设置unclean.leader.election.enable=false 当leader副本发生故障时不会从follower副本中和leader同步程度达不到要求的副本中选举出leader，降低了消息丢失的可能性
- kafka如何保证消息不重复消费
  - **出现消息重复消费的原因**
    - 服务端侧已经成功消费的数据没有成功提交offset(根本原因)
    - kafka侧由于服务端处理业务时间长或者网络连接等等原因让kafka认为服务器假死，触发了分区
  - 解决方案
    - 消费消息服务做幂等校验 ，redis的set和mysql的主键等天然的幂等功能
    - 关闭自动提交
      - 处理完消息再提交：依旧有消息重复消息的风险， 和自动提交一样
      - 拉取到消息即提交：会有消息丢失的风险。允许消息延时的场景，一般采用该方法。通过定时任务在业务不繁忙的时候做数据兜底

### RabbitMQ
- 核心概念
  - 整体上是一个生产者和消费者模型，主要负责接收、存储和转发消息。从计算机术语层面来说，rabbitmq模型更像是一种交换机模型
  - Producer 生产者 生产消息的一方
  - Consumer 消费者 消费消息的一方
  - 消息一般由两部分组成：消息头和消息体，消息头有一系列可选属性组成，包括路由键、优先权、持久性存储等。生产者把消息交由Rabbitmq后，会根据消息头把消息发送给感兴趣的消费者。消息体是不透明的
  - Exchange 交换器
    - 在Rabbitmq中，**消息并不是直接被投递到Queue中的，中间还必须经过Exchange(交换器)这一层，Exchange会把我们的消息分配到对应的消息队列中**
    - **Exchange用来接收生产者发送的消息并将这些消息路由给服务器中的队列中，如果路由不到，或许会返回给Producer，或许会被直接丢弃掉**。生产者将消息发给交换器的时候，一般都会指定RoutingKey(路由键)，用来指定这个消息的路由规则，**这个RoutingKey需要与交换器类型和绑定键(BindingKey)联合使用才能生效**
    - 


### Nacos 注册中心
- 服务跨集群调用
  - 服务调用尽可能选择本地集群的服务，跨集群调用延迟较高
  - 本地集群不可访问时，再去访问其他集群
- 分级存储模型
  - 一级是服务  
  - 二级是集群
  - 三级是实例
- NacosRule负载均衡策略
  - 优先选择同集群服务实例列表
  - 本地集群找不到提供者，才会去其他集群寻找，并会发生警告
  - 确定了可用实例列表后，再采用随机负载均衡挑选实例
  - nacos提供了权重配置来控制访问频率，权重越大则访问频率越高，权重设置为0时则完全不会被访问
- nacos中服务存储和数据存储的最外层都是一个名为namespace的东西，用来做最外层隔离  
  - namespace用来做环境隔离，namespace都有一个独有的id，不同的namespace下的服务不可见
- nacos **针对临时实例，采用心跳检测，需要临时实例自己发请求确保自己还存活，nacos还会干掉该临时实例，剔除服务**；针对非临时实例，**nacos主动询问，主动进行检测**，当服务提供者实例宕机了将状态变为不健康的，**但不会剔除服务，并主动推送消息给服务消费者**。
  - nacos支持服务列表变更的消息推送模式，服务列表更新更及时




## 高可用
### 高可用系统设计指南
- 高可用描述得是一个系统在大部分是可用的，可以为我们提供服务。高可用代表系统即使在发生硬件故障或者系统升级得时候，服务仍然是可用的
- **导致系统不可用的情况**
  - 黑客攻击
  - 硬件故障，服务器坏掉
  - 并发/用户请求量激增导致整个服务宕机掉或者部分服务不可用
  - 程序本身问题 内存泄漏
  - 网站架构种某个角色不可用，nginx不可用或者数据库突然不可用
  - 自然灾害或者人为破坏
- 提高系统可用性的方法
  - 注重代码质量，测试严格把关
  - **使用集群，减少单点故障**
    - 保证redis集群的高可用性
  - **限流**
    - 当应用流量达到指定的阈值时对流量进行控制，以避免被顺势的流量高峰冲垮，保证系统可用性
  - 超时和重试机制设置
    - 设置合适的超时时间和重试次数
  - **熔断机制**
    - 系统自动收集所依赖服务的资源使用情况和性能指标，当所依赖的服务恶化或者调用失败次数达到某个阈值的时候就迅速事变，让当前系统立即切换依赖其他备份服务
  - **异步调用**
    - 异步调用不用关心最后的结果，用户请求完成之后就立即返回结果。除了实现异步调用之外，还可以使用消息队列，**消息队列可以通过异步处理提高系统性能**(削峰，减少响应所需时间)并且可以降低系统耦合性
  - 使用缓存
    - 使用缓存缓存热点数据，缓存是存储在内存中的
  - 核心应用和服务优先使用更好的硬件
  - 监控系统添加报警设置
  - 注意备份
  - 灰度发布
  - 定期检查和更换硬件

### 冗余设计
- 冗余设计是保证系统和数据高可用的常用手段
- 对于服务来说，冗余的思想就是相同的服务部署多份，如果正在使用的服务突然挂掉的话，系统可以很快切换到备份服务上，大大减少了系统的不可用时间，提高了系统的可用性
- 对于数据来说，冗余的思想就是相同的数据备份多份，这样可以简单提高数据的安全性
- **高可用集群、同城灾备、异地灾备、同城多活和异地多活**是冗余思想在高可用系统设计种最典型的应用
- 故障转移就是实现不可用服务快速且自动地切换到可用服务，不需要认为干涉

### 服务限流
- 限流就是对请求的速率进行限制，避免瞬时的大量请求击垮软件系统。限流可能导致用户的请求无法被正确处理
- 常见的限流算法
  - **固定窗口计数器算法**
    - 固定窗口计数器算法规定了单位时间处理的请求数量  这种限流算法无法保证限流速率，因而无法保证突然激增的流量
  - **滑动窗口计数器算法**
    - 把时间以一定比例进行分片， 滑动窗口的格子划分越多，滑动窗口的滚动就会更加平滑，限流统计就会更加精确
  - **漏桶算法**
    - 把发请求的动作比作注水到桶中，我们处理请求的过程可以必煜为漏桶漏水。我们往桶中以任意速率流入水，以一定速率流出水。当水超过桶容量则丢弃，桶容量是不变的，保证了整体的速率。
    - 准备一个队列来保存请求，定期从队列中拿请求来执行就行，和消息队列削峰/限流的思想一样
  - 令牌桶算法
    - 现在桶中装的是令牌，请求在被处理之前需要拿到一块令牌，请求处理完毕之后将这个令牌丢弃。我们根据限流大小，按照一定的速率往桶里面添加令牌。如果桶满了就不能继续往里面添加令牌了。
- 单机限流
  - 直接使用限流工具类
- 分布式限流
  - 借助中间件架限流 使用redis来实现对应的限流逻辑
  - 网关层限流 ，但是网关层限流通常也要借助到中间件/框架
  - **redis+lua实现限流**
    - 减少了网络开销  lua脚本来批量执行多条redis命令，这些命令会被提交到redis服务器一次性执行完毕，大幅减小了网络开销
    - 原子性  一段lua脚本执行过程中不会有其他脚本或者redis命令同时执行，保证了操作不会被其他指令插入或者打扰

### 超时&重试机制
- 为了最大限度的减小系统或者服务出现故障之后带来的影响，需要用到超时和重试机制， **如果没有设置超时的话，就可能导致服务端连接数爆炸和大量请求堆积的问题，这些堆积的连接和请求会消耗资源，影响新收到的请求的处理，严重情况下会拖累整个系统和服务**
- 超时机制：当一个请求超过指定时间还没有被处理的话，这个请求就会直接被取消并抛出指定的异常或者错误，比如504 
  - 连接超时：客户端与服务端建立连接的最长等待时间
  - 读取超时：客户端和服务端已经建立连接，客户端等待服务端处理完请求的最长时间。
  - 超时时间太高，降低超时设置的有效性，依然存在大量慢请求堆积的问题；超时时间太低，导致系统或者服务在某些处理请求速度变慢的情况下，大量请求重试，加重系统压力。
  - 超时时间可以设置为1500ms，具体情况具体分析
- 重试机制： 重试机制一般配合超时机制一起使用，指的是多次发送相同的请求来避免瞬态故障和偶然性故障
  - 瞬态故障是一瞬间系统偶然出现故障，并不会持久。偶然性故障为那些在某些情况偶尔出现的故障，频率通常较低
  - 重试的核心是通过消耗服务器的资源来尽可能获得请求更大概率被成功处理。
  - 重试的次数通常设置为3次，并且还设置重试间隔。
  - **重试幂等**
    - 超时和重试机制在实际项目中使用的话，需要注意保证同一个请求没有被多次执行
    - 出现一个请求被多次执行的情况：客户端等待服务端完成请求完成超时单此时服务端已经执行了请求，只是短暂的网络波动导致响应在发送给客户端的过程中延迟了
